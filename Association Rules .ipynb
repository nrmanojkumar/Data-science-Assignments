{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578209d2-36bb-4690-ac03-e85ed157adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9926b705-3540-410e-bb90-3e2ccc11a02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786213a5-f90d-41d1-bdc9-4bbe918a31c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openpyxlNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 3.1.2\n",
      "Summary: A Python library to read/write Excel 2010 xlsx/xlsm files\n",
      "Home-page: https://openpyxl.readthedocs.io\n",
      "Author: See AUTHORS\n",
      "Author-email: charlie.clark@clark-consulting.eu\n",
      "License: MIT\n",
      "Location: C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\n",
      "Requires: et-xmlfile\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "pip show openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f134f59-9921-45fe-b243-8bafac76553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from an Excel file\n",
    "file_path = 'Online retail.xlsx'  # Ensure the file path is correct\n",
    "data = pd.read_excel(file_path, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6b3263-76ff-4f18-bc93-f97efaf12fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500 entries, 0 to 7499\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                                                                                                                                                           Non-Null Count  Dtype \n",
      "---  ------                                                                                                                                                                                                                           --------------  ----- \n",
      " 0   shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil  7500 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 58.7+ KB\n",
      "None\n",
      "  shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil\n",
      "0                             burgers,meatballs,eggs                                                                                                                                                                             \n",
      "1                                            chutney                                                                                                                                                                             \n",
      "2                                     turkey,avocado                                                                                                                                                                             \n",
      "3  mineral water,milk,energy bar,whole wheat rice...                                                                                                                                                                             \n",
      "4                                     low fat yogurt                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "# Display basic information and the first few rows of the dataset\n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1faf06ea-ffb4-4bab-a8df-fa2bd01c9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (Make sure the path and method are correct)\n",
    "file_path = 'Online retail.xlsx'\n",
    "data = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be647665-b9b0-47dd-ae33-f8f8e7e457cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Correctly print the summary of missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa38c255-af68-4b9d-95d5-53ecc3550ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: One or more specified columns are not in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Correct implementation to remove rows with missing values in critical columns\n",
    "if 'InvoiceNo' in data.columns and 'Description' in data.columns and 'CustomerID' in data.columns:\n",
    "    # Only remove rows where any of these critical columns are missing\n",
    "    data.dropna(subset=['InvoiceNo', 'Description', 'CustomerID'], inplace=True)\n",
    "    print(\"\\nAfter removing missing values:\")\n",
    "    print(data.isnull().sum())\n",
    "else:\n",
    "    print(\"Error: One or more specified columns are not in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bfc1f25-3fb5-4fff-99eb-4362e5bf9c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data preview:\n",
      "  shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil\n",
      "0                             burgers,meatballs,eggs                                                                                                                                                                             \n",
      "1                                            chutney                                                                                                                                                                             \n",
      "2                                     turkey,avocado                                                                                                                                                                             \n",
      "3  mineral water,milk,energy bar,whole wheat rice...                                                                                                                                                                             \n",
      "4                                     low fat yogurt                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "# Optionally, check the output to ensure rows are dropped correctly\n",
    "print(\"\\nData preview:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2968ea9d-91dc-4a6f-9f7b-1628ad8c401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate entries\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed23fd9-80b9-4c89-8f5a-ece7784ebebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: Index(['shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming data has been loaded and cleaned appropriately\n",
    "print(\"Columns in DataFrame:\", data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56adfff6-0294-449c-b020-f81e42b11052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'InvoiceNo' column not found.\n"
     ]
    }
   ],
   "source": [
    "# Convert InvoiceNo to string format, if not already\n",
    "if 'InvoiceNo' in data.columns:\n",
    "    data['InvoiceNo'] = data['InvoiceNo'].astype(str)\n",
    "else:\n",
    "    print(\"Error: 'InvoiceNo' column not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45e6aaf7-28a1-4b9e-ae93-f316d84dccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping filtering since 'InvoiceNo' column is missing.\n"
     ]
    }
   ],
   "source": [
    "# Filter out any non-purchase transactions (like returns)\n",
    "if 'InvoiceNo' in data.columns:\n",
    "    data = data[~data['InvoiceNo'].str.contains('C')]  \n",
    "else:\n",
    "    print(\"Skipping filtering since 'InvoiceNo' column is missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe2ff8cc-ba77-4522-bc2a-ed1c82b12068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preview after filtering:   shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil\n",
      "0                             burgers,meatballs,eggs                                                                                                                                                                             \n",
      "1                                            chutney                                                                                                                                                                             \n",
      "2                                     turkey,avocado                                                                                                                                                                             \n",
      "3  mineral water,milk,energy bar,whole wheat rice...                                                                                                                                                                             \n",
      "4                                     low fat yogurt                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "# Check again what we have in the DataFrame\n",
    "print(\"Data preview after filtering:\", data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46ded3ed-f21f-4b86-8587-fdc2e1c5c02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Necessary columns are missing for basket transformation.\n"
     ]
    }
   ],
   "source": [
    "# Create a basket format dataframe\n",
    "if 'InvoiceNo' in data.columns and 'Description' in data.columns:\n",
    "    basket = (data\n",
    "              .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "              .sum().unstack().reset_index().fillna(0)\n",
    "              .set_index('InvoiceNo'))\n",
    "else:\n",
    "    print(\"Error: Necessary columns are missing for basket transformation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80d3cf52-6e47-4999-a763-c8e43bb6673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basket transformation was not done due to earlier errors.\n"
     ]
    }
   ],
   "source": [
    "# Convert quantities to 1s and 0s, if basket was created\n",
    "if 'basket' in locals():\n",
    "    basket_sets = basket.applymap(lambda x: 1 if x >= 1 else 0)\n",
    "    print(\"Basket sets created successfully.\")\n",
    "else:\n",
    "    print(\"Basket transformation was not done due to earlier errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60c7c4ac-6e17-4f8c-9b61-f7b80e08fa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basket sets were not created due to earlier errors, nothing to save.\n"
     ]
    }
   ],
   "source": [
    "# Check if 'basket_sets' is defined and save it\n",
    "if 'basket_sets' in locals():\n",
    "    # Define the file path where you want to save the CSV\n",
    "    output_file_path = 'preprocessed_basket_sets.csv'  # You can change the path as needed\n",
    "\n",
    "    # Save to CSV\n",
    "    basket_sets.to_csv(output_file_path, index=True)  # Keeping the InvoiceNo as index\n",
    "    print(f\"Data successfully saved to {output_file_path}\")\n",
    "else:\n",
    "    print(\"Basket sets were not created due to earlier errors, nothing to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b4a1c72-6572-4da2-bdfc-7282dcf25875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from mlxtend) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from mlxtend) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from mlxtend) (1.4.1.post1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from mlxtend) (3.8.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=1.0.2->mlxtend) (3.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f521773-f989-4257-8f75-b7e17327ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Assuming 'data' is loaded as before and it contains the transactions\n",
    "# Let's simulate loading this unusual data format\n",
    "data = pd.DataFrame({\n",
    "    'items': [\n",
    "        \"burgers, meatballs, eggs\",\n",
    "        \"chutney\",\n",
    "        \"turkey, avocado\",\n",
    "        \"mineral water, milk, energy bar, whole wheat rice, green tea\",\n",
    "        \"low fat yogurt\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "932263c1-bc08-48ca-9c99-b37cac73296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the items in each row and expand into a list\n",
    "data['items'] = data['items'].str.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0e1d4fb-1a40-4634-998a-ec43d110b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the encoder\n",
    "encoder = TransactionEncoder()\n",
    "transaction_data = list(data['items'])\n",
    "transaction_array = encoder.fit(transaction_data).transform(transaction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7294313-45cb-44f0-a15d-e7ba0d177a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avocado  burgers  chutney   eggs  energy bar  green tea  low fat yogurt  \\\n",
      "0    False     True    False   True       False      False           False   \n",
      "1    False    False     True  False       False      False           False   \n",
      "2     True    False    False  False       False      False           False   \n",
      "3    False    False    False  False        True       True           False   \n",
      "4    False    False    False  False       False      False            True   \n",
      "\n",
      "   meatballs   milk  mineral water  turkey  whole wheat rice  \n",
      "0       True  False          False   False             False  \n",
      "1      False  False          False   False             False  \n",
      "2      False  False          False    True             False  \n",
      "3      False   True           True   False              True  \n",
      "4      False  False          False   False             False  \n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the one-hot encoded format\n",
    "basket_sets = pd.DataFrame(transaction_array, columns=encoder.columns_)\n",
    "\n",
    "print(basket_sets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e161261f-3911-403f-97e1-021c55d748b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = 'preprocessed_basket_sets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f1587b3-8b25-41e0-bc08-f9dbe028be69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to preprocessed_basket_sets.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "basket_sets.to_csv(output_file_path, index=False)  \n",
    "print(f\"Data successfully saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7e5ddbc-2421-439b-ac26-889f270dcbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "data = pd.read_csv('preprocessed_basket_sets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55769e7e-cb8b-4f0b-8010-36a5e48dea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Apriori algorithm to find frequent itemsets\n",
    "# Adjust the min_support threshold as needed to find meaningful patterns\n",
    "frequent_itemsets = apriori(data, min_support=0.01, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a4d203e-7804-4a47-be98-57f4e091d9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   support      itemsets\n",
      "0      0.2     (avocado)\n",
      "1      0.2     (burgers)\n",
      "2      0.2     (chutney)\n",
      "3      0.2        (eggs)\n",
      "4      0.2  (energy bar)\n"
     ]
    }
   ],
   "source": [
    "# Print the frequent itemsets\n",
    "print(frequent_itemsets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91d0dc1d-514c-4686-bb0f-6a45c6496929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the rules with their corresponding support, confidence, and lift\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4a3a19f-ed0a-4f75-b7ca-78a78feb97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rules based on lift, confidence, and support\n",
    "# Adjust thresholds as per the requirement to refine the rule quality\n",
    "filtered_rules = rules[(rules['lift'] >= 2) & (rules['confidence'] >= 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfc47113-05dd-4f1f-a94a-7286ca810a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            antecedents                                        consequents  \\\n",
      "0              (turkey)                                          (avocado)   \n",
      "1             (avocado)                                           (turkey)   \n",
      "2                (eggs)                                          (burgers)   \n",
      "3             (burgers)                                             (eggs)   \n",
      "4             (burgers)                                        (meatballs)   \n",
      "..                  ...                                                ...   \n",
      "189     (mineral water)    (milk, green tea, energy bar, whole wheat rice)   \n",
      "190         (green tea)  (milk, mineral water, energy bar, whole wheat ...   \n",
      "191        (energy bar)  (milk, mineral water, green tea, whole wheat r...   \n",
      "192              (milk)  (mineral water, green tea, energy bar, whole w...   \n",
      "193  (whole wheat rice)       (milk, mineral water, green tea, energy bar)   \n",
      "\n",
      "     antecedent support  consequent support  support  confidence  lift  \\\n",
      "0                   0.2                 0.2      0.2         1.0   5.0   \n",
      "1                   0.2                 0.2      0.2         1.0   5.0   \n",
      "2                   0.2                 0.2      0.2         1.0   5.0   \n",
      "3                   0.2                 0.2      0.2         1.0   5.0   \n",
      "4                   0.2                 0.2      0.2         1.0   5.0   \n",
      "..                  ...                 ...      ...         ...   ...   \n",
      "189                 0.2                 0.2      0.2         1.0   5.0   \n",
      "190                 0.2                 0.2      0.2         1.0   5.0   \n",
      "191                 0.2                 0.2      0.2         1.0   5.0   \n",
      "192                 0.2                 0.2      0.2         1.0   5.0   \n",
      "193                 0.2                 0.2      0.2         1.0   5.0   \n",
      "\n",
      "     leverage  conviction  zhangs_metric  \n",
      "0        0.16         inf            1.0  \n",
      "1        0.16         inf            1.0  \n",
      "2        0.16         inf            1.0  \n",
      "3        0.16         inf            1.0  \n",
      "4        0.16         inf            1.0  \n",
      "..        ...         ...            ...  \n",
      "189      0.16         inf            1.0  \n",
      "190      0.16         inf            1.0  \n",
      "191      0.16         inf            1.0  \n",
      "192      0.16         inf            1.0  \n",
      "193      0.16         inf            1.0  \n",
      "\n",
      "[194 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the filtered rules\n",
    "print(filtered_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc92fc2f-81dd-4c02-b210-feb04b523dd6",
   "metadata": {},
   "source": [
    "Understanding and Interpreting Association Rules\n",
    "\n",
    "To effectively interpret the generated rules, concentrate on the metrics of support, confidence, and lift:\n",
    "\n",
    " * Support: This metric shows the frequency of the itemset in the data. A high support value means the itemset is common.\n",
    " * Confidence: This metric represents the probability of item Y being bought when item X is bought. This is a conditional probability.\n",
    " * Lift: This metric indicates how often items X and Y are purchased together compared to if they were statistically independent. A lift value greater than 1 suggests that the items are likely to be bought together. You can sort and filter the rules based on these metrics to identify the most relevant and strong rules.\n",
    "   \n",
    "Look for interesting patterns such as:\n",
    "\n",
    " * Frequent item combinations: These are items that often appear together in transactions.\n",
    " * High-confidence rules: These are rules where the presence of one set of items significantly increases the likelihood of another item being purchased.\n",
    " * High-lift values: These are especially valuable as they suggest a strong relationship between items beyond simple co-occurrence due to their individual popularity.\n",
    "   \n",
    "From the filtered rules, you can derive insights about customer purchasing behavior:\n",
    "\n",
    " * Product Bundling: Identify opportunities for marketing strategies such as product bundling or promotions. For example, if bread and butter have high lift and confidence together, a promotion might be run on one when the other is bought.\n",
    " * Store Layout: Use the association of items to influence store layout, placing items that are frequently bought together in close proximity, thus enhancing the shopping experience and potentially increasing sales.\n",
    " * Targeted Marketing: Customize marketing campaigns to focus on the likelihood of cross-selling products based on these insights. For example, customers buying gluten-free pasta might also be interested in other gluten-free products.\n",
    " * Customer Segmentation: Segment customers based on the types of products they buy together, allowing for more personalized marketing and improved customer service.\n",
    " * Inventory Management: Adjust inventory levels based on the frequency and confidence of certain items being bought together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
